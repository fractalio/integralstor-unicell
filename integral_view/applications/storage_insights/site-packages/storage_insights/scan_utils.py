import os
import json
import time
import platform

from integralstor import db, command, config, datetime_utils, filesize

import checksum_utils

scan_killed = False


def get_scan_configurations(db_location = None, scan_configuration_id = None, standalone = False, include_deleted=False):
    configurations = None
    try:
        if not db_location:
            db_location, err = get_db_location(standalone)
            if err:
                raise Exception(err)
        if scan_configuration_id:
            query = 'select * from scan_configurations where id="%d"'%scan_configuration_id
        else:
            query = 'select * from scan_configurations'
        if not include_deleted:
            if scan_configuration_id:
                query += ' and status_id != -1'
            else:
                query += ' where status_id != -1'
        #print query
        configurations, err = db.get_multiple_rows(db_location, query)
        if err:
            raise Exception(err)
        for c in configurations:
            query = 'select count(*) as num_files, sum(size) as total_size, count(distinct(extension)) as num_extensions from file_info where scan_configuration_id="%d"'%c['id']
            row, err = db.get_single_row(db_location, query)
            if err:
                raise Exception(err)
            row['total_size_human_readable'] = '0'
            if row:
                if not row['total_size']:
                    row['total_size'] = 0
                row['total_size_human_readable'] = filesize.get_naturalsize(row['total_size'])
                c.update(row)
    except Exception, e:
        return None, 'Error loading Storage Insights configurations : %s'%str(e)
    else:
        return configurations, None

def get_db_details(standalone = False):
    db_details = None
    try:
        db_details = {}
        db_location, err = get_db_location(standalone)
        if err:
            raise Exception(err)
        size = os.path.getsize(db_location)
        db_details['size'] = size
        db_details['size_str'] = filesize.get_naturalsize(size)
        query = 'select count(*) as count from file_info'
        row, err = db.get_single_row(db_location, query)
        if err:
            raise Exception(err)
        db_details['num_files'] = row['count']

    except Exception, e:
        return None, 'Error loading Storage Insights database details : %s'%str(e)
    else:
        return db_details, None


def create_scan_configuration(config_dict, standalone = False):
    try:
        db_location, err = get_db_location(standalone)
        if err:
            raise Exception(err)
        configs, err = get_scan_configurations(db_location=db_location, include_deleted=True)
        if err:
            raise Exception(err)
        for c in configs:
            if c['scan_dir'] == config_dict['scan_dir']:
                raise Exception('A configuration for that scan folder already exists.')
            if c['scan_dir'].strip().rstrip('/') in config_dict['scan_dir'].strip().rstrip('/'):
                raise Exception('A configuration  (scan folder "%s") for a parent folder of that scan folder already exists. Please expunge it before creating.'%c['scan_dir'])
            if config_dict['scan_dir'].strip().rstrip('/') in c['scan_dir'].strip().rstrip('/') :
                raise Exception('The specified scan folder is the parent of an existing  configuration (scan folder "%s"). Please expunge it before creating.'%c['scan_dir'])

        if 'exclude_dirs' in config_dict and config_dict['exclude_dirs']:
            cmd = [
                'insert into scan_configurations(scan_dir, exclude_dirs, generate_checksum, record_history, db_transaction_size, status_id) values (?,?, ?,?,?,?)', (config_dict['scan_dir'], config_dict['exclude_dirs'], config_dict['generate_checksum'], config_dict['record_history'], config_dict['db_transaction_size'], 2)]
        else:
            cmd = [
                'insert into scan_configurations(scan_dir, generate_checksum, record_history, db_transaction_size, status_id) values (?,?,?,?,?)', (config_dict['scan_dir'], config_dict['generate_checksum'], config_dict['record_history'], config_dict['db_transaction_size'], 2)]
        ret, err = db.execute_iud(db_location, [cmd])
        if err:
            raise Exception(err)
    except Exception, e:
        return False, 'Error creating Storage Insights configuration : %s'%str(e)
    else:
        return True, None

def delete_scan_configuration(scan_configuration, standalone = False, type = 'mark_deleted'):
    try:
        db_location, err = get_db_location(standalone)
        if err:
            raise Exception(err)
        if type == 'expunge':
            cmd = ['delete from file_info where scan_configuration_id="%d"'%scan_configuration['id']]
            ret, err = db.execute_iud(db_location, [cmd])
            if err:
                raise Exception(err)
            cmd = ['delete from file_events_history where scan_configuration_id="%d"'%scan_configuration['id']]
            ret, err = db.execute_iud(db_location, [cmd])
            if err:
                raise Exception(err)
            cmd = ['delete from scans where scan_configuration_id="%d"'%scan_configuration['id']]
            ret, err = db.execute_iud(db_location, [cmd])
            if err:
                raise Exception(err)
            cmd = ['delete from scan_configurations where id="%d"'%scan_configuration['id']]
            ret, err = db.execute_iud(db_location, [cmd])
            if err:
                raise Exception(err)
        else:
            cmd = [
                'update scan_configurations set status_id="-1" where id="%d"'%scan_configuration['id']]
        ret, err = db.execute_iud(db_location, [cmd])
        if err:
            raise Exception(err)
    except Exception, e:
        return False, 'Error removing Storage Insights configuration : %s'%str(e)
    else:
        return True, None


def get_db_location(standalone = False):
    location = None
    try:
        if not standalone:
            app_root, err = config.get_application_root('storage_insights')
            if err:
                raise Exception(err)
            db_path = '%s/db'%app_root
        else:
            db_path = '.'
        location = '%s/storage_insights.db'%db_path
        if not os.path.exists(location):
            raise Exception('Database not found in : %s'%db_path)

    except Exception, e:
        return None, 'Error loading Storage Insights database : %s'%str(e)
    else:
        return location, None

def get_scans(scan_id=None, standalone = False):
    scan_list = []
    try:
        db_location, err = get_db_location(standalone)
        if err:
            raise Exception(err)
        query = 'select scans.*, scan_configurations.scan_dir, scan_configurations.exclude_dirs from scans, scan_configurations where scans.scan_configuration_id=scan_configurations.id'
        if scan_id:
            query = '%s and scans.id = "%d"'%(query, int(scan_id))
        query = "%s order by scan_dir, initiate_time desc"%query
        #print query
        scan_list, err = db.get_multiple_rows(db_location, query)
        if err:
            raise Exception(err)
        if scan_list:
            ref_scan_status_list, err = db.get_multiple_rows(db_location, 'select * from reference_scan_status')
            if err:
                raise Exception(err)
            for scan in scan_list:
                '''
                query = 'select * from scan_configurations where id="%d"'%scan['scan_configuration_id']
                scan_config, err = db.get_single_row(db_location, query)
                if err:
                    raise Exception(err)
                scan['scan_dir'] = scan_config['scan_dir']
                '''
                tm_str, err = datetime_utils.convert_from_epoch(scan['initiate_time'], return_format='str', str_format='%c', to='local')
                if err:
                    raise Exception(err)
                scan['initiate_time_str'] = tm_str
                if ref_scan_status_list:
                    for rcs in ref_scan_status_list:
                        if rcs['id'] == scan['status_id']:
                            scan['status_desc'] = rcs['description']
                            break
    except Exception, e:
        return None, 'Error retrieving Storage Insights scan information : %s'%str(e)
    else:
        return scan_list, None

def delete_scan(scan_id, standalone = False):
    try:
        db_location, err = get_db_location(standalone)
        if err:
            raise Exception(err)
        cmd = [
            'delete from scans where id="%d"'%scan_id]
        ret, err = db.execute_iud(db_location, [cmd])
        if err:
            raise Exception(err)
    except Exception, e:
        return False, 'Error removing Storage Insights scan details : %s'%str(e)
    else:
        return True, None

def update_cron_schedule(scan_configuration_id, cron_task_id):
    try:
        db_location, err = get_db_location(standalone=False)
        if err:
            raise Exception(err)
        query = 'update scan_configurations set cron_task_id="%d" where id="%d"'%(cron_task_id, scan_configuration_id)
        print query
        scan_list, err = db.execute_iud(db_location, [[query]])
        if err:
            raise Exception(err)
    except Exception, e:
        return False, 'Error updating  Storage Insights scan schedule information : %s'%str(e)
    else:
        return True, None


def signal_handler(signum, stack):
    try:
        print 'Received a terminate signal so cleaning up and exiting.'
        global scan_killed
        scan_killed = True
    except Exception, e:
        print 'Error handling exception : %s'%str(e)
    else:
        return True, None

def log_scan_start(db_location, scan_configuration, pid):
    scan_id = 0
    try:

        pltfrm = None
        try:
            pltfrm = platform.uname()[0]
        except Exception, e:
            pass

        if pltfrm and pltfrm.lower() == 'linux':
            running_pid, err = get_running_process_pid()
            if err:
                raise Exception(err)
            if running_pid > 0:
                raise Exception('A Storage Insights scan process with process id %d is currently running. Only one scan process can run at one time. Exiting now.'%running_pid)
        pid = os.getpid()
        if pltfrm and pltfrm.lower() == 'linux':
            if not os.path.exists('/var/run/integralstor/applications'):
                os.makedirs('/var/run/integralstor/applications')
            with open('/var/run/integralstor/applications/storage_insights_scan', 'w') as f:
                f.write('%d'%pid)

        query = 'select * from scans where scan_configuration_id="%d" and status_id=1'%scan_configuration['id']
        rows, err = db.get_multiple_rows(db_location, query)
        if err:
            raise Exception(err)
        if rows:
            #DB says there is a process running so mark it as error and then start a new one..
            cmd = ['update scans set status_id=4, status_str="Process killed" where id = "%d"'%rows[0]['id']]
            ret, err = db.execute_iud(db_location, [cmd], get_rowid=False)
            if err:
                raise Exception(err)

        #!!!!!!!!!!!!CHANGE TO USE INTEGRALSTOR's CALLS
        initiate_time = int(time.time())
        #No existing pending runs so create a new run entry
        cmd = ['insert into scans(initiate_time, scan_configuration_id, pid, status_id) values (?,?,?,?)', (initiate_time, scan_configuration['id'], pid, 1,)]
        scan_id, err = db.execute_iud(db_location, [cmd], get_rowid=True)
        if err:
            raise Exception(err)
    except Exception, e:
        return None, 'Error logging scan run start information : %s'%str(e)
    else:
        return scan_id, None

def log_scan_progress(db_location, params_dict):
    try:
        #print params_dict
        if 'status_id' not in params_dict:
            raise Exception('Incomplete call')

        required_params = ['status_str', 'scan_id']
        if params_dict['status_id'] != 4:
            required_params.extend(['scanned_dirs_count', 'scanned_files_count', 'successful_creation_modification_transactions_count','failed_creation_modification_transactions_count', 'successful_deletion_transactions_count', 'failed_deletion_transactions_count', 'new_files_count', 'modified_files_count'])
        if not all(param in params_dict for param in required_params):
            raise Exception('Incomplete call')

        if params_dict['status_id'] == 4:
            #It is a kill so dont log the counts..
            cmd = ['update scans set status_id=?, status_str=? where id = ?', (params_dict['status_id'], params_dict['status_str'], params_dict['scan_id'],)]
        else:
            cmd = ['update scans set status_id=?, status_str=?, scanned_dirs_count=?, scanned_files_count=?, successful_creation_modification_transactions_count=?, failed_creation_modification_transactions_count=?, successful_deletion_transactions_count=?, failed_deletion_transactions_count=?, new_files_count=?, modified_files_count=?, deleted_files_count=? where id = ?', (params_dict['status_id'], params_dict['status_str'], params_dict['scanned_dirs_count'], params_dict['scanned_files_count'], params_dict['successful_creation_modification_transactions_count'], params_dict['failed_creation_modification_transactions_count'], params_dict['successful_deletion_transactions_count'], params_dict['failed_deletion_transactions_count'], params_dict['new_files_count'], params_dict['modified_files_count'], params_dict['deleted_files_count'], params_dict['scan_id'],)]

        #print cmd
        ret, err = db.execute_iud(db_location, [cmd], get_rowid=False)
        if err:
            raise Exception(err)
    except Exception, e:
        print e
        return False, 'Error logging scan run completion information : %s'%str(e)
    else:
        return True, None

def get_running_process_pid():
    pid = 0
    try:
        if os.path.exists('/var/run/integralstor/applications/storage_insights_scan'):
            with open('/var/run/integralstor/applications/storage_insights_scan', 'r') as f:
                pid_str = f.read()
            if pid_str:
                pid = int(pid_str)
        if pid > 0:
            try:
                os.kill(pid, 0)
            except Exception, e:
                #The process no longer exists so we can return a 0
                try:
                    os.remove('/var/run/integralstor/applications/storage_insights_scan')
                except Exception, e:
                    pass
                pid = 0

    except Exception, e:
        return None, 'Error checking for existing Storage Insights scan process : %s'%str(e)
    else:
        return pid, None



#This function should NOT be called from a django request as it requires a PID
def initiate_scan(scan_configuration_id, standalone = False):
    scan_id = 0
    db_location = None
    conn = None
    error_list = []
    successful_creation_modification_transactions_count = 0
    failed_creation_modification_transactions_count = 0
    successful_deletion_transactions_count = 0
    failed_deletion_transactions_count = 0
    scanned_files_count = 0
    scanned_dirs_count = 0
    new_files_count = 0
    modified_files_count = 0
    deleted_files_count = 0
    try:

        global scan_killed
        scan_killed = False
        print '-----------------------------SETTINGS---------------------------------'

        db_location, err = get_db_location(standalone)
        if err:
            raise Exception(err)
        configs, err = get_scan_configurations(db_location = db_location, scan_configuration_id = scan_configuration_id, standalone = standalone, include_deleted=False)
        if err:
            raise Exception(err)
        if not configs:
            raise Exception('Specified configuration does not exist')
    

        scan_dir = configs[0]['scan_dir']
        exclude_dirs = configs[0]['exclude_dirs']
        generate_checksum = configs[0]['generate_checksum']
        db_transaction_size = configs[0]['db_transaction_size']
        record_history = configs[0]['record_history']

        if generate_checksum:
            print 'Generating file checksums'
        else:
            print 'Not generating file checksums'
        if record_history:
            print 'Recording file event history'
        else:
            print 'Not recording file event history'
        dir_str = 'Collecting statistics for the folder : %s..\n'%scan_dir
        exclude_dirs_list = None
        if exclude_dirs:
            dir_str += '..but excluding the following directories : "%s"'%exclude_dirs
            exclude_dirs_list = []
            components = exclude_dirs.split(',')
            for component in components:
                exclude_dirs_list.append('%s/%s'%(scan_dir, component.strip().lstrip('/')))
        print dir_str
        print '----------------------------------------------------------------------'


        pid = os.getpid()
        scan_id, err = log_scan_start(db_location, configs[0], pid)
        if err:
            raise Exception(err)

        counter = 0
        cmd_list = []
        transaction_file_list = []
        if not os.path.exists(scan_dir):
            raise Exception('Specified scan directory %s does not exist.'%scan_dir)
        print 'Collecting information about the directory structure for %s..'%scan_dir
        for root, dirs, files in os.walk(unicode(scan_dir)):
            if scan_killed:
                break
            scanned_dirs_count += 1
            #print 'Processing directory %s'%root
            if exclude_dirs_list and root in exclude_dirs_list:
                #Config says exclude this dir so skip it.
                print 'Skipping excluded directory : %s'%root
                continue
            for file in files:
                full_path = os.path.normpath('%s/%s'%(root, file))
                #print full_path
                try:
                    db_to_be_updated = False
                    scanned_files_count += 1
                    transaction_file_list.append(full_path)
                    if os.path.islink(full_path):
                        continue
                    extension = None
                    if full_path:
                        rt, extension = os.path.splitext(full_path)
                    mtime = os.path.getmtime(full_path)
                    #print 'mtime', mtime
                    size = os.path.getsize(full_path)
                    chksum = None
                    if generate_checksum:
                        chksum, err = checksum_utils.generate_checksum(full_path, algorithm = 'sha256')
                        if err:
                            error_list.append((full_path, err))
                            print '!!!!', err
                            continue

                    #First check if we have some recorded info about this file.
                    query = 'select * from file_info where path = "%s"'%full_path
                    file_info_row, err = db.get_single_row(db_location, query)
                    if err:
                        raise Exception(err)

                    #Now decide whether to insert/update the DB..
                    insert_update_file_info = False
                    update_file_info = False
                    if not file_info_row:
                        #Info not in the DB so insert..
                        #Insert it if the path does not exist or else ignore.. 
                        cmd = ['insert or ignore into file_info(path, extension, size, checksum, last_modify_time, last_access_time, last_scan_id, scan_configuration_id) values (?,?,?,?,?,?,?,?)', (full_path, extension, size, chksum, int(mtime), int(mtime),scan_id, scan_configuration_id,)]
                        cmd_list.append(cmd)
                        new_files_count += 1
                        db_to_be_updated = True
                    else:
                        #Exists in DB but has anything changed with the file?? If so, update
                        if file_info_row['last_modify_time'] != int(mtime):
                            #File mtime does not match whats in the DB so modify
                            update_file_info = True
                        if generate_checksum:
                            if file_info_row['checksum'] != chksum:
                                #File checksum does not match whats in the DB so modify
                                update_file_info = True
                        if update_file_info:
                            modified_files_count += 1
                            #This file has NOT been processed already in a previous run of the same scan_id 
                            if generate_checksum:
                                update_cmd = ['update file_info set size=?, last_modify_time=?, last_access_time=?, extension=?, checksum=?, last_scan_id = ?, scan_configuration_id=? where path = ?', (size, int(mtime), int(mtime), extension, chksum, scan_id, scan_configuration_id, full_path,)]
                            else:
                                update_cmd = ['update file_info set size=?, last_modify_time=?, last_access_time=?, extension=?, last_scan_id=?, scan_configuration_id=? where path = ?', (size, int(mtime), int(mtime), extension, scan_id, scan_configuration_id, full_path,)]
                            cmd_list.append(update_cmd)
                            db_to_be_updated = True
                    if record_history:
                        cmd = ['insert or ignore into file_events_history(file_info_id, path, events, event_time, last_scan_id, scan_configuration_id) values ((select id from file_info where path=?),?,?,?,?, ?)', (full_path, full_path, 'MODIFY', int(mtime), scan_id, scan_configuration_id, )]
                        cmd_list.append(cmd)
                        db_to_be_updated = True
                    if db_to_be_updated:
                        counter += 1
                    if cmd_list and (counter != 0) and (counter % db_transaction_size == 0):
                        print 'Scanned %d files'%scanned_files_count
                        #print cmd_list
                        ret, err = db.execute_iud(db_location, cmd_list, get_rowid=False)
                        #print ret, err
                        if err:
                            failed_creation_modification_transactions_count += counter
                            for transaction_file in transaction_file_list:
                                error_list.append((transaction_file, 'Error inserting/updating into the database : %s'%err))
                        else:
                            successful_creation_modification_transactions_count += counter
                            pd = {'scan_id': scan_id, 'status_id':1, 'status_str':'Scanned %d directories and %d files. Processed %d creations/modifilcation transactions successfully with %d errors. New files detected : %d, files modified since last scan : %d'%(scanned_dirs_count, scanned_files_count, successful_creation_modification_transactions_count, failed_creation_modification_transactions_count, new_files_count, modified_files_count), 'scanned_dirs_count': scanned_dirs_count, 'scanned_files_count': scanned_files_count, 'successful_creation_modification_transactions_count':successful_creation_modification_transactions_count, 'failed_creation_modification_transactions_count':failed_creation_modification_transactions_count, 'successful_deletion_transactions_count' : successful_deletion_transactions_count, 'failed_deletion_transactions_count':failed_deletion_transactions_count, 'new_files_count':new_files_count, 'modified_files_count':modified_files_count, 'deleted_files_count' : deleted_files_count}
                            ret, err = log_scan_progress(db_location, pd)
                        cmd_list = []
                        transaction_file_list = []
                        counter = 0
                except Exception, e:
                    #print e
                    error_list.append((full_path, str(e)))
        if not scan_killed:
            if cmd_list:
                print 'Processing the last batch of %d files.'%counter
                #print cmd_list
                #Still have unprocessed files so insert them!
                ret, err = db.execute_iud(db_location, cmd_list, get_rowid=False)
                if err:
                    failed_creation_modification_transactions_count += counter
                    for transaction_file in transaction_file_list:
                        error_list.append((transaction_file, 'Error inserting into the database : %s'%err))
                else:
                    successful_creation_modification_transactions_count += counter
            pd = {'scan_id': scan_id, 'status_id':1, 'status_str':'Processed all creations and modifications. Now processing deletions. Scanned %d directories and %d files. Processed %d creation/modification transactions successfully with %d errors'%(scanned_dirs_count, scanned_files_count, successful_creation_modification_transactions_count, failed_creation_modification_transactions_count), 'scanned_dirs_count': scanned_dirs_count, 'scanned_files_count': scanned_files_count, 'successful_creation_modification_transactions_count':successful_creation_modification_transactions_count, 'failed_creation_modification_transactions_count':failed_creation_modification_transactions_count, 'successful_deletion_transactions_count' : successful_deletion_transactions_count, 'failed_deletion_transactions_count':failed_deletion_transactions_count, 'new_files_count':new_files_count, 'modified_files_count':modified_files_count, 'deleted_files_count' : deleted_files_count}
            ret, err = log_scan_progress(db_location, pd)

            #Now scan for deleted files that are in our db but have actually been deleted..
            print 'scanning for deletes'
            query = 'select * from file_info where scan_configuration_id="%d" and last_scan_id != "%d"'%(scan_configuration_id, scan_id)
            (cur, conn), err = db.get_query_cursor_and_connection(db_location, query)
            if err:
                raise Exception(err)
            file_info_row, err = db.get_next_row(cur)
            if err:
                raise Exception(err)
            cmd_list = []
            transaction_file_list = []
            while file_info_row:
                if not os.path.isfile(file_info_row['path']):
                    #File no longer exists so delete the file_info entry and put in a delete into the file_events_history table
                    deleted_files_count += 1
                    transaction_file_list.append(file_info_row['path'])
                    if record_history:
                        #!!!!!!!!!!!!CHANGE TO USE INTEGRALSTOR's CALLS
                        now_time = int(time.time())
                        #cmd_list.append(['insert into file_events_history(path, events, event_time, last_scan_id, scan_configuration_id) values (?,?,?,?, ?)', (full_path, 'DELETE', int(now_time), scan_id, scan_configuration_id, )])
                        cmd_list.append(['insert or ignore into file_events_history(file_info_id, path, events, event_time, last_scan_id, scan_configuration_id) values ((select id from file_info where path=?),?,?,?,?, ?)', (file_info_row['path'], file_info_row['path'], 'DELETE', int(now_time), scan_id, scan_configuration_id, )])
                    cmd_list.append(['delete from file_info where id="%d"'%file_info_row['id']])
                #Now read the next row
                file_info_row, err = db.get_next_row(cur)
                if err:
                    raise Exception(err)
            if conn:
                db.close_connection(conn)
            #print cmd_list
            if cmd_list:
                print cmd_list
                ret, err = db.execute_iud(db_location, cmd_list)
                print ret, err
                if err:
                    failed_deletion_transactions_count += counter
                    for transaction_file in transaction_file_list:
                        error_list.append((transaction_file, 'Error inserting into the database : %s'%err))
                    raise Exception(err)
                else:
                    successful_deletion_transactions_count += counter
            if failed_creation_modification_transactions_count > 0 or failed_deletion_transactions_count > 0:
                status_id = 3
            else:
                status_id = 2
            pd = {'scan_id': scan_id, 'status_id':status_id, 'status_str':'Processed all creation/modification/deletion changes. %d file creations, %d file modifications and %d file deletions detected. %d failed creation/modification transactions and %d failed deletion transactions. '%(new_files_count, modified_files_count, deleted_files_count, failed_creation_modification_transactions_count, failed_deletion_transactions_count), 'scanned_dirs_count': scanned_dirs_count, 'scanned_files_count': scanned_files_count, 'successful_creation_modification_transactions_count':successful_creation_modification_transactions_count, 'failed_creation_modification_transactions_count':failed_creation_modification_transactions_count, 'successful_deletion_transactions_count' : successful_deletion_transactions_count, 'failed_deletion_transactions_count':failed_deletion_transactions_count, 'new_files_count':new_files_count, 'modified_files_count':modified_files_count, 'deleted_files_count' : deleted_files_count}
            print 'a'
            ret, err = log_scan_progress(db_location, pd)
            print ret, err
            print 'aa'
        else:
            time_str = time.strftime('%a, %d %b %Y %H:%M:%S')
            pd = {'scan_id': scan_id, 'status_id':4, 'status_str':'Paused at %s'%time_str}
            ret, err = log_scan_progress(db_location, pd)
    except Exception, e:
        print e
        if scan_id != 0 and db_location:
            pd = {'scan_id': scan_id, 'status_id':-1, 'status_str':'Error : %s'%str(e), }
            ret, err = log_scan_progress(db_location, pd)
        return False, 'Error collecting statistics : %s'%str(e), error_list, -1, -1, -1, -1, -1, -1, -1, -1, -1
    else:
        return True, None, error_list, scanned_dirs_count, scanned_files_count, successful_creation_modification_transactions_count, failed_creation_modification_transactions_count, successful_deletion_transactions_count, failed_deletion_transactions_count, new_files_count, modified_files_count, deleted_files_count
    finally:
        if conn:
            db.close_connection(conn)

if __name__ == '__main__':
    #print get_scan_configurations(include_deleted=True)
    print get_scans()
    pass
# vim: tabstop=8 softtabstop=0 expandtab ai shiftwidth=4 smarttab
