from integralstor_utils import db, config, scheduler_utils


def _replication_modes():
    """Maintains the list of available modes for remote replication

    args:       None
    returns:    A list containing available modes
    """
    # Modularity at the cost of redundancy
    modes = []
    try:
        modes = ['zfs', 'rsync']
    except Exception, e:
        return None, str(e)
    else:
        return modes, None


def get_replication_modes():
    """Gets the available modes of remote replication

    args:       None
    returns:    A list containing available modes
    """

    modes = []
    try:
        ret, err = _replication_modes()
        if err:
            raise Exception(err)
        if not ret:
            raise Exception('No replication mode found')
        modes = ret
    except Exception, e:
        return None, str(e)
    else:
        return modes, None


def add_remote_replication(mode, entries):
    """Add remote replication entries to respective tables

    - add replication entry to remote_replications table
    - call replication mode(zfs,rsync) specific functions to add other
      required entries to respective mode specific tables

    args:       - mode           # string type replication mode
                - entries        # A dictionary with required mode
                                   specific values

    returns:    - a dictionary containing cron_task_id and 
                  remote_replication_id if the run was successful, None
                  otherwise.
                - Error string if the run failed or if exceptions were
                  raised, None otherwise.
    """
    remote_replication_id = None
    try:
        if not (mode and entries):
            raise Exception('Invalid parameters')

        modes, err = get_replication_modes()
        if err:
            raise Exception(err)
        if mode not in modes:
            raise Exception('Invalid replication mode: %s' % mode)

        if ('description' and 'schedule') not in entries:
            raise Exception('Invalid parameters')

        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)

        # Since cron_task_id is a required parameter pass -1 to
        # represent its unavailability. Update when available.
        cron_task_id = -1

        # Insert in to remote_replications is followed by insert in to
        # appropriate mode specific replication table.
        rr_cmd = "insert into remote_replications (cron_task_id,mode) values ('%d','%s')" % (
            cron_task_id, mode)
        remote_replication_id, err = db.execute_iud(
            db_path, [[rr_cmd], ], get_rowid=True)
        if err:
            raise Exception(err)

        if mode == 'zfs':
            ids, err = _add_zfs_remote_replication(
                remote_replication_id, entries)
            if err:
                raise Exception(err)
            if ids and ids['cron_task_id']:
                cron_task_id = ids['cron_task_id']
        elif mode == 'rsync':
            ids, err = _add_rsync_remote_replication(
                remote_replication_id, entries)
            if err:
                raise Exception(err)
            if ids and ids['cron_task_id']:
                cron_task_id = ids['cron_task_id']

        if (not remote_replication_id) or (not cron_task_id):
            raise Exception('remote_replication_id or cron_task_id is unavailable')

    except Exception, e:
        return None, 'Error adding a remote replication task: %s' % e
    else:
        return {'remote_replication_id': remote_replication_id, 'cron_task_id': cron_task_id}, None


def _add_rsync_remote_replication(remote_replication_id, entries):
    """Add rsync replication and cron entries

    - add rsync replication fields to rsync_replications table
    - add cron entry that runs rsync replication at the scheduled time

    args:       - remote_replication_id 
                - entries        # A dictionary with required rsync
                                   specific values

    returns:    - a dictionary containing cron_task_id and 
                  rsync_remote_replication_id if the run was successful
                  None otherwise.
                - Error string if the run failed or if exceptions were
                  raised, None otherwise.
    """
    try:
        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)
        py_scripts_path, err = config.get_python_scripts_path()
        if err:
            raise Exception(err)

        if ('rsync_type' and 'short_switches' and 'long_switches' and 'source_path' and 'target_path' and 'target_ip' and 'target_user_name') not in entries:
            raise Exception('Invalid parameters')

        rsync_repl_cmd = "insert into rsync_replications (remote_replication_id,rsync_type,short_switches,long_switches,source_path,target_path,target_ip,target_user_name) values ('%d','%s','%s','%s','%s','%s','%s','%s')" % (
            remote_replication_id, entries['rsync_type'], entries['short_switches'], entries['long_switches'], entries['source_path'], entries['target_path'], entries['target_ip'], entries['target_user_name'])

        rsync_remote_replication_id, err = db.execute_iud(
            db_path, [[rsync_repl_cmd], ], get_rowid=True)
        if err:
            # If insert to rsync_replications table fails, remove the
            # appropriate entry from remote_replications to avoid
            # dangling/invalid entries in the table.
            revert_cmd = "delete from remote_replications where remote_replication_id='%s'" % remote_replication_id
            rowid, er = db.execute_iud(
                db_path, [[revert_cmd], ], get_rowid=False)
            # revert is a best effort, so, no exceptions raised.
            raise Exception('%s' % err)

        schedule = entries['schedule']
        cmd = '%s/run_rsync_remote_replication.py %s' % (
            py_scripts_path, remote_replication_id)

        # this cron entry executes the rsync replication python script
        # which in turn calls another function to run(queues) the rsync
        # replication of the specified remote_replication_id
        cron_task_id, err = scheduler_utils.create_cron_task(
            cmd, entries['description'], schedule[0], schedule[1], schedule[2], schedule[3], schedule[4])
        if err:
            raise Exception(err)

        # Update cron_task_id which was previously set as -1
        cmd = "update remote_replications set cron_task_id='%d' where remote_replication_id='%s'" % (
            cron_task_id, remote_replication_id)
        rowid, err = db.execute_iud(db_path, [[cmd], ], get_rowid=True)
        if err:
            raise Exception(
                'Scheduling remote replication unsuccessfull: %s' % err)

        if (not rsync_remote_replication_id) or (not cron_task_id):
            raise Exception(
                'rsync_remote_replication_id or cron_task_id is unavailable')

    except Exception, e:
        return None, 'Error adding rsync remote replication task: %s' % e
    else:
        return {'rsync_remote_replication_id': rsync_remote_replication_id, 'cron_task_id': cron_task_id}, None


def _add_zfs_remote_replication(remote_replication_id, entries):
    """Add ZFS replication and cron entries

    - add ZFS replication fields to zfs_replications table
    - add cron entry that runs ZFS replication at the scheduled time

    args:       - remote_replication_id 
                - entries        # A dictionary with required ZFS
                                   specific values

    returns:    - a dictionary containing cron_task_id and 
                  zfs_remote_replication_id if the run was successful
                  None otherwise.
                - Error string if the run failed or if exceptions were
                  raised, None otherwise.
    """
    try:
        if ('source_dataset' and 'target_pool' and 'target_ip' and 'target_user_name') not in entries:
            raise Exception('Invalid parameters')

        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)
        py_scripts_path, err = config.get_python_scripts_path()
        if err:
            raise Exception(err)

        zfs_repl_cmd = "insert into zfs_replications (remote_replication_id,source_dataset,target_pool,target_ip,target_user_name) values ('%d','%s','%s','%s','%s')" % (
            remote_replication_id, entries['source_dataset'], entries['target_pool'], entries['target_ip'], entries['target_user_name'])

        zfs_remote_replication_id, err = db.execute_iud(
            db_path, [[zfs_repl_cmd], ], get_rowid=True)
        if err:
            # If insert to zfs_replications table fails, remove the
            # appropriate entry from remote_replications to avoid
            # dangling/invalid entries in the table.
            revert_cmd = "delete from remote_replications where remote_replication_id='%s'" % remote_replication_id
            rowid, er = db.execute_iud(
                db_path, [[revert_cmd], ], get_rowid=False)
            # revert is a best effort, so, no exceptions raised.
            raise Exception('%s' % err)

        schedule = entries['schedule']
        cmd = '%s/run_zfs_remote_replication.py %s' % (
            py_scripts_path, remote_replication_id)

        # this cron entry executes the ZFS replication python script
        # which in turn calls another function to run(queues) the ZFS
        # replication of the specified remote_replication_id
        cron_task_id, err = scheduler_utils.create_cron_task(
            cmd, entries['description'], schedule[0], schedule[1], schedule[2], schedule[3], schedule[4])
        if err:
            raise Exception(err)

        # Update cron_task_id which was previously set as -1
        cmd = "update remote_replications set cron_task_id='%d' where remote_replication_id='%s'" % (
            cron_task_id, remote_replication_id)
        rowid, err = db.execute_iud(db_path, [[cmd], ], get_rowid=True)
        if err:
            raise Exception(
                'Scheduling remote replication unsuccessfull: %s' % err)

        if (not zfs_remote_replication_id) or (not cron_task_id):
            raise Exception(
                'zfs_remote_replication_id or cron_task_id is unavailable')

    except Exception, e:
        return None, 'Error adding zfs remote replication task: %s' % e
    else:
        return {'zfs_remote_replication_id': zfs_remote_replication_id, 'cron_task_id': cron_task_id}, None


def update_remote_replication_schedule(remote_replication_id, schedule):
    try:
        if not (remote_replication_id and schedule):
            raise Exception('Invalid arguments')

        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)
        replications, err = get_remote_replications(
            remote_replication_id)
        if err:
            raise Exception(err)
        if not replications:
            raise Exception('Specified replication definition not found')

        cron_task_id = None
        if 'cron_task_id' in replications[0]:
            cron_task_id = replications[0]['cron_task_id']
        else:
            raise Exception('Cron task ID unavailable')

        is_update, err = scheduler_utils.update_cron_schedule(
            cron_task_id, 'root', schedule[0], schedule[1], schedule[2], schedule[3], schedule[4])
        if err:
            raise Exception(err)

    except Exception, e:
        return False, 'Error updating remote replication schedule: %s' % e
    else:
        return True, None


def delete_remote_replication(remote_replication_id):
    try:
        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)

        replications, err = get_remote_replications(
            remote_replication_id)
        # replications must contain only one entry since
        # remote_replication_id will have a single unique entry.
        if err:
            raise Exception(err)
        if not replications:
            raise Exception(
                'Specified remote replication not found')

        cron_remove, err = scheduler_utils.delete_cron(
            int(replications[0]['cron_task_id']))
        if err:
            raise Exception(err)

        # Uncomment the following block if 'ON DELETE CASCADE' switch
        # is removed from the replication related tables in the DB
        """
        # Reverting a delete is not possible. If this fails, we will
        # end up with dangling entries. Better to remove from
        # remote_replications table first because they used for display
        # in views. A dangling entry in remote_replications table is
        # very misleading, but one in mode specific tables is not so
        # problematic since they aren't used for listing in
        # IntegralView directly.
        rr_cmd = "delete from remote_replications where remote_replication_id='%s'" % remote_replication_id
        rowid, err = db.execute_iud(db_path, [[rr_cmd], ], get_rowid=False)
        if err:
            raise Exception(err)

        if replications[0]['mode'] == 'zfs':
            zfs_cmd = "delete from zfs_replications where remote_replication_id='%s'" % remote_replication_id
            rowid, err = db.execute_iud(
                db_path, [[zfs_cmd], ], get_rowid=False)
            if err:
                raise Exception(err)
        elif replications[0]['mode'] == 'rsync':
            rsync_cmd = "delete from rsync_replications where remote_replication_id='%s'" % remote_replication_id
            rowid, err = db.execute_iud(
                db_path, [[rsync_cmd], ], get_rowid=False)
            if err:
                raise Exception(err)
        """

    except Exception, e:
        return False, 'Error deleting remote replication task: %s' % e
    else:
        return True, None


def delete_all_remote_replications():
    """Delete all scheduled remote replications and respective cron table entries.

    """
    error_list = []
    try:
        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)

        replications, err = get_remote_replications()
        if err:
            raise Exception(err)
        for replication in replications:
            ret, err = delete_remote_replication(
                int(replication['remote_replication_id']))
            if err:
                error_list.append(err)

        if error_list:
            raise Exception(str(error_list))
    except Exception, e:
        return False, 'Error deleting remote replication tasks : %s' % e
    else:
        return True, None


def get_remote_replications(remote_replication_id=None):
    replications = []
    try:
        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)

        if remote_replication_id is not None:
            cmd = "select * from remote_replications where remote_replication_id='%s'" % remote_replication_id
        else:
            cmd = "select * from remote_replications"
        replications, err = db.get_multiple_rows(db_path, cmd)
        if err:
            raise Exception(err)

        if replications is not None:
            for replication in replications:
                cron_tasks, err = scheduler_utils.get_cron_tasks(
                    replication['cron_task_id'])
                if err:
                    raise Exception(err)
                if not cron_tasks:
                    raise Exception('Specified replication schedule not found')
                replication['schedule_description'] = cron_tasks[0]['schedule_description']
                replication['description'] = cron_tasks[0]['description']
                mode_cmd = "select * from %s_replications where remote_replication_id='%s'" % (
                    replication['mode'], replication['remote_replication_id'])
                mode_repl, err = db.get_multiple_rows(db_path, mode_cmd)
                if err:
                    raise Exception(err)
                if mode_repl is not None:
                    mode = replication['mode']
                    replication[mode] = mode_repl

    except Exception, e:
        return None, 'Error retrieving remote replications : %s' % e
    else:
        return replications, None


def get_remote_replications_with(mode, entries):
    replications = []
    repls = []
    try:
        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)
        modes, err = get_replication_modes()
        if err:
            raise Exception(err)
        if mode and mode not in modes:
            raise Exception('Invalid replication mode: %s' % mode)
        # TODO: generalize 'entries' parameter values
        if mode == 'zfs':
            cmd = "select * from zfs_replications where source_dataset='%s' and target_ip='%s' and target_pool='%s'" % (
                entries['source_dataset'], entries['target_ip'], entries['target_pool'])
            replications, err = db.get_multiple_rows(db_path, cmd)
            if err:
                raise Exception(err)
        elif mode == 'rsync':
            cmd = "select * from rsync_replications where source_path='%s' and target_ip='%s' and target_path='%s'" % (
                entries['source_path'], entries['target_ip'], entries['target_path'])
            replications, err = db.get_multiple_rows(db_path, cmd)
            if err:
                raise Exception(err)

        if replications is not None:
            for replication in replications:
                repl, err = get_remote_replications(
                    replication['remote_replication_id'])
                if err:
                    raise Exception(err)
                repls.append(repl)

    except Exception, e:
        return None, 'Error retrieving remote replications : %s' % e
    else:
        return repls, None


def run_rsync_remote_replication(description, entries):
    """Queues the replication to tasks table

    The header says 'run' though it actually only queues it and doesn't
    execute it right away. When queued, it runs the following minute.
    """
    try:
        scripts_path, err = config.get_shell_scripts_path()
        if err:
            raise Exception(err)
        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)

        # replications that involve interactions with remote machines
        # are done as 'replicator' user.
        # Requires SSH key exchange to successfully get through with
        # the communications
        # NOTE: SSH key exchange is not handled here
        run_as_user_name = 'replicator'
        rsync_type = entries['rsync_type']
        source_path = entries['source_path']
        target_path = entries['target_path']
        short_switches = entries['short_switches']
        long_switches = entries['long_switches']
        remote_ip = entries['target_ip']
        remote_user_name = entries['target_user_name']

        rr, err = get_remote_replications_with('rsync',
                                               {'source_path': source_path, 'target_ip': remote_ip, 'target_path': target_path})
        if err:
            raise Exception(err)
        if not rr:
            raise Exception(
                'Could not locate the specified remote replication task')

        # Check for active replication tasks
        existing_tasks, err = scheduler_utils.get_tasks_by_cron_task_id(
            rr[0][0]['cron_task_id'])
        if err is not None:
            raise Exception(err)
        if existing_tasks:
            for task in existing_tasks:
                if str(task['status']) == "running" and str(task['task_type_id']) == "4":
                    raise Exception(
                        "Will not commence the replication; a background task with the same description is yet to complete its replication!")

        cmd_arg = ''
        source = ''
        target = ''
        if rsync_type == 'pull':
            source = '%s@%s:%s' % (
                remote_user_name, remote_ip, source_path)
            target = target_path
        elif rsync_type == 'push':
            target = '%s@%s:%s' % (
                remote_user_name, remote_ip, target_path)
            source = source_path
        elif rsync_type == 'local':
            target = target_path
            source = source_path
            # since rsync type 'local' is with in the machine
            run_as_user_name = 'integralstor'

        if rsync_type in ['push', 'pull']:
            cmd_arg = 'sudo rsync -hivOP %s %s --stats --exclude=urbackup_tmp_files -e \\"ssh -l replicator -i /home/replicator/.ssh/id_rsa -o ServerAliveInterval=300 -o ServerAliveCountMax=3\\" %s %s' % (
                short_switches, long_switches, source, target)
        elif rsync_type in ['local']:
            cmd_arg = 'rsync -hivOP %s %s --stats --exclude=urbackup_tmp_files %s %s' % (
                short_switches, long_switches, source, target)

        path = '%s/rsync_replicator.sh' % scripts_path
        cmd = '/bin/bash %s "%s"' % (path, cmd_arg)

        # Retry upto 3 times(default) with a retry interval of 1 hour
        ret, err = scheduler_utils.create_task(description, [
            {'Replication': cmd}], task_type_id=4, run_as_user_name=run_as_user_name, retry_interval=60, cron_task_id=rr[0][0]['cron_task_id'])
        if err:
            raise Exception(err)
    except Exception, e:
        return False, 'Error processing/executing rsync remote replication: %s' % e
    else:
        return True, None


def run_zfs_remote_replication(description, entries):
    """Queues the replication to tasks table

    The header says 'run' though it actually only queues it and doesn't
    execute it right away. When queued, it runs the following minute.
    """
    try:
        scripts_path, err = config.get_shell_scripts_path()
        if err:
            raise Exception(err)
        db_path, err = config.get_db_path()
        if err:
            raise Exception(err)

        # replications that involve interactions with remote machines
        # are done as 'replicator' user.
        # Requires SSH key exchange to successfully get through with
        # the communications
        # NOTE: SSH key exchange is not handled here
        run_as_user_name = 'replicator'
        source_dataset = entries['source_dataset']
        target_ip = entries['target_ip']
        target_pool = entries['target_pool']
        target_user_name = entries['target_user_name']
        pos = source_dataset.find("/")
        if pos == -1:
            raise Exception('Invalid dataset name')
        source_pool = source_dataset[:pos]
        source_dataset_name = source_dataset[(pos + 1):]

        rr, err = get_remote_replications_with('zfs',
                                               {'source_dataset': source_dataset, 'target_ip': target_ip, 'target_pool': target_pool})
        if err:
            raise Exception(err)
        if not rr:
            raise Exception(
                'Could not locate the specified remote replication task')

        # Check for active replication tasks
        existing_tasks, err = scheduler_utils.get_tasks_by_cron_task_id(
            rr[0][0]['cron_task_id'])
        if err is not None:
            raise Exception(err)
        if existing_tasks:
            for task in existing_tasks:
                if str(task['status']) == "running" and str(task['task_type_id']) == "4":
                    raise Exception(
                        "Will not commence the replication; a background task with the same description is yet to complete its replication!")

        path = '%s/replicator.sh' % scripts_path
        cmd = "/bin/bash %s %s %s %s %s %s" % (
            path, source_pool, source_dataset_name, target_pool, target_user_name, target_ip)

        # Retry upto 3 times(default) with a retry interval of 1 hour
        ret, err = scheduler_utils.create_task(description, [
            {'Replication': cmd}], task_type_id=4, run_as_user_name=run_as_user_name, retry_interval=60, cron_task_id=rr[0][0]['cron_task_id'])
        if err:
            raise Exception(err)

    except Exception, e:
        return False, 'Error processing/executing ZFS remote replication : %s' % e
    else:
        return True, None


if __name__ == "__main__":
    # print schedule_remote_replication("Replication of try-try/send to pool zpool on machine 192.168.1.212", "try-try/send", "192.168.1.212", "replicator", "zpool")
    # print schedule_remote_replication("Replication of try-try/send to pool
    # zpool on machine 192.168.1.212","test-pool/test-send", "192.168.1.129",
    # "replicator", "p1")
    # def schedule_remote_replication(description, mode, entries):
    # print schedule_remote_replication("Replication of try-try/ds to pool dd
    # on machine 12.12.12.12", 'zfs', {'source_dataset':'try-try/ds',
    # 'target_ip':'12.12.12.12', 'target_user_name':'replicator',
    # 'target_pool':'dd'})
    print get_remote_replications(29)
    pass

# vim: tabstop=8 softtabstop=0 expandtab ai shiftwidth=4 smarttab
